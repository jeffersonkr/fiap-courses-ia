{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yns7z1dooSiw",
        "colab_type": "text"
      },
      "source": [
        "# Exercício\n",
        "\n",
        "---\n",
        "- Treine um modelo de classificação DecisionTreeClassifier do pacote scikit-learn para classificar os produtos em suas categorias.\n",
        "- Experimente a lib SpaCy para remover as stop words e reduzir as palavras a seu lema. Veja como essas alterações impactam o desempenho do classificador.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhkRPtt4mxf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8'\n",
        "  ).sample(frac=0.5, random_state=42)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df[\"texto\"] = df['nome'] + \" \" + df['descricao']\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                   nome  \\\n33                                      Extraordinário    \n3316   Fifa 2018 Narração Português Completo Midia D...   \n1557   Kit Mega Sarutobi Kunai Naruto Asuma Shuriken...   \n2548   Caixa 50 Cores Batom Queen Fosco Matte Nude K...   \n457    Box Dourado Crónica De Gelo E Fogo Edição De ...   \n\n                                              descricao  categoria  \\\n33    Produto Novo“Extraordinário” é um livro que co...      livro   \n3316  FIFA 2018 - XBOX 360 MIDIA DIGITAL COMPLETOATE...       game   \n1557  Descrição do Kit Ninja (Foto):Uma Kunai Asuma ...  brinquedo   \n2548  CAIXA C/ 50 CORES DIFERENTES!BATOM MATTE QUEEN...  maquiagem   \n457   A série Crônicas de Gelo e apresentações. São ...      livro   \n\n                                                  texto  \n33     Extraordinário  Produto Novo“Extraordinário” ...  \n3316   Fifa 2018 Narração Português Completo Midia D...  \n1557   Kit Mega Sarutobi Kunai Naruto Asuma Shuriken...  \n2548   Caixa 50 Cores Batom Queen Fosco Matte Nude K...  \n457    Box Dourado Crónica De Gelo E Fogo Edição De ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nome</th>\n      <th>descricao</th>\n      <th>categoria</th>\n      <th>texto</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33</th>\n      <td>Extraordinário</td>\n      <td>Produto Novo“Extraordinário” é um livro que co...</td>\n      <td>livro</td>\n      <td>Extraordinário  Produto Novo“Extraordinário” ...</td>\n    </tr>\n    <tr>\n      <th>3316</th>\n      <td>Fifa 2018 Narração Português Completo Midia D...</td>\n      <td>FIFA 2018 - XBOX 360 MIDIA DIGITAL COMPLETOATE...</td>\n      <td>game</td>\n      <td>Fifa 2018 Narração Português Completo Midia D...</td>\n    </tr>\n    <tr>\n      <th>1557</th>\n      <td>Kit Mega Sarutobi Kunai Naruto Asuma Shuriken...</td>\n      <td>Descrição do Kit Ninja (Foto):Uma Kunai Asuma ...</td>\n      <td>brinquedo</td>\n      <td>Kit Mega Sarutobi Kunai Naruto Asuma Shuriken...</td>\n    </tr>\n    <tr>\n      <th>2548</th>\n      <td>Caixa 50 Cores Batom Queen Fosco Matte Nude K...</td>\n      <td>CAIXA C/ 50 CORES DIFERENTES!BATOM MATTE QUEEN...</td>\n      <td>maquiagem</td>\n      <td>Caixa 50 Cores Batom Queen Fosco Matte Nude K...</td>\n    </tr>\n    <tr>\n      <th>457</th>\n      <td>Box Dourado Crónica De Gelo E Fogo Edição De ...</td>\n      <td>A série Crônicas de Gelo e apresentações. São ...</td>\n      <td>livro</td>\n      <td>Box Dourado Crónica De Gelo E Fogo Edição De ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STMWVw3dsBOl",
        "colab_type": "code",
        "outputId": "50452a82-4c58-42aa-8878-eb8efa515358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "df.categoria.value_counts()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "livro        411\nmaquiagem    387\nbrinquedo    328\ngame         298\nName: categoria, dtype: int64"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMG-cnHho8pi",
        "colab_type": "code",
        "outputId": "467f9018-131b-41b3-ac0d-9537ea18a1a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Exemplo 1: Vetorização por contagem de termos simples com unigrama, sem stopwords do NLTK e modelo de classificação DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import nltk\n",
        "\n",
        "# stopwords NLTK\n",
        "nltk.download('stopwords')\n",
        "stops = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "# vetorização por contagem de termos\n",
        "#vect = CountVectorizer(ngram_range=(1,1)) # exemplo 1.1: vetorização unigrama com stopwords\n",
        "vect = CountVectorizer(ngram_range=(1,1), stop_words=stops) # exemplo 1.2: vetorização unigrama sem stopwords\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "# divisão da amostra entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "      text_vect, \n",
        "      df[\"categoria\"], \n",
        "      test_size = 0.2, \n",
        "      random_state = 42\n",
        "  )\n",
        "\n",
        "# treinamento do modelo ávore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "y_prediction = tree.predict(X_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "accuracy = accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\jeffe\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n(1424, 23418)\n0.9543859649122807\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiFf6cRWXRkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install spacy\n",
        "#!python -m spacy download pt\n",
        "#!python -m spacy download en"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBkhv7TJpPRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# função de lematização completa do documento\n",
        "def lemmatizer_text(text):        \n",
        "  sent = []\n",
        "  doc = nlp(text)\n",
        "  for word in doc:\n",
        "      sent.append(word.lemma_)\n",
        "  return \" \".join(sent)\n",
        "\n",
        "# função de lematização para os verbos do documento\n",
        "def lemmatizer_verbs(text):        \n",
        "  sent = []\n",
        "  doc = nlp(text)\n",
        "  for word in doc:\n",
        "      if word.pos_ == \"VERB\":\n",
        "          sent.append(word.lemma_)\n",
        "      else:\n",
        "          sent.append(word.orth_)\n",
        "  return \" \".join(sent)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV5GVlPFq-rG",
        "colab_type": "code",
        "outputId": "1a2e100f-dd69-4c6f-cb08-189541b46817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# teste das funções de lematização\n",
        "import spacy\n",
        "nlp = spacy.load('pt_core_news_sm')\n",
        "\n",
        "print(lemmatizer_text('correndo 1, 2, 3'))\n",
        "print(lemmatizer_verbs('correndo 1, 2, 3'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "correr 1 , 2 , 3\ncorrer 1 , 2 , 3\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLz7qvbj2WVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# aplica a lematização no dataframe\n",
        "df['text_lemma'] = df.texto.apply(lemmatizer_text)\n",
        "df['text_lemma_verbs'] = df.texto.apply(lemmatizer_verbs)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8jQNEBhUeOW",
        "colab_type": "code",
        "outputId": "97a3d1f5-a1fb-4e77-c8eb-b952ae38d8fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "print(df.info())\n",
        "print('\\nshape: ', df.shape)\n",
        "print(df.head(2))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1424 entries, 33 to 2615\nData columns (total 6 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   nome              1424 non-null   object\n 1   descricao         1424 non-null   object\n 2   categoria         1424 non-null   object\n 3   texto             1424 non-null   object\n 4   text_lemma        1424 non-null   object\n 5   text_lemma_verbs  1424 non-null   object\ndtypes: object(6)\nmemory usage: 77.9+ KB\nNone\n\nshape:  (1424, 6)\n                                                   nome  \\\n33                                      Extraordinário    \n3316   Fifa 2018 Narração Português Completo Midia D...   \n\n                                              descricao categoria  \\\n33    Produto Novo“Extraordinário” é um livro que co...     livro   \n3316  FIFA 2018 - XBOX 360 MIDIA DIGITAL COMPLETOATE...      game   \n\n                                                  texto  \\\n33     Extraordinário  Produto Novo“Extraordinário” ...   \n3316   Fifa 2018 Narração Português Completo Midia D...   \n\n                                             text_lemma  \\\n33      Extraordinário   Produto Novo“Extraordinário...   \n3316    Fifa 2018 Narração Português Completo Midia ...   \n\n                                       text_lemma_verbs  \n33      Extraordinário   Produto Novo“Extraordinário...  \n3316    Fifa 2018 Narração Português Completo Midia ...  \n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rabyoXjzQCn",
        "colab_type": "code",
        "outputId": "f1077bcb-797a-4f00-ac6d-dee739234076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(df['texto'][0])\n",
        "print(df['text_lemma'][0])\n",
        "print(df['text_lemma_verbs'][0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bolseiro é um hobbit que leva uma vida confortável e sem ambições. Mas seu contentamento é perturbado quando Gandalf, o mago, e uma companhia de anões batem à sua porta e levam-no para uma expedição. Eles têm um plano para roubar o tesouro guardado por Smaug, o Magnífico, um grande e perigoso dragão. Bilbo reluta muito em participar da aventura, mas acaba surpreendendo até a si mesmo com sua esperteza e sua habilidade como ladrão!CaracterísticasAutor: Tolkien, J. R. R.Peso: 0.44I.S.B.N.: 9788578277109Altura: 20.000000Largura: 13.000000Profundidade: 1.000000Número de Páginas: 328Idioma: PortuguêsAcabamento: BrochuraNúmero da edição: 7Ano da edição: 2013\n  O Hobbit - 7ª Ed . 2013   Produto NovoBilbo Bolseiro ser um hobbit que levar umar vidar confortável e sem ambição . Mas seu contentamento ser perturbar quando Gandalf , o mago , e umar companhia de anão bater à suar portar e levam-no parir umar expedição . Eles ter um planar parir roubar o tesourar guardar por Smaug , o Magnífico , um grande e perigoso dragão . Bilbo relutar muito em participar da aventurar , mas acabar surpreender até o si mesmo com suar esperteza e suar habilidade comer ladrão!CaracterísticasAutor : Tolkien , J. R. R.Peso : 0.44I.S.B.N. : 9788578277109Altura : 20.000000Largura : 13.000000Profundidade : 1.000000Número de Páginas : 328Idioma : PortuguêsAcabamento : BrochuraNúmero da edição : 7Ano da edição : 2013\n  O Hobbit - 7ª Ed . 2013   Produto NovoBilbo Bolseiro ser um hobbit que levar uma vida confortável e sem ambições . Mas seu contentamento é perturbar quando Gandalf , o mago , e uma companhia de anões bater à sua porta e levam-no para uma expedição . Eles ter um plano para roubar o tesouro guardar por Smaug , o Magnífico , um grande e perigoso dragão . Bilbo relutar muito em participar da aventura , mas acaba surpreender até a si mesmo com sua esperteza e sua habilidade como ladrão!CaracterísticasAutor : Tolkien , J. R. R.Peso : 0.44I.S.B.N. : 9788578277109Altura : 20.000000Largura : 13.000000Profundidade : 1.000000Número de Páginas : 328Idioma : PortuguêsAcabamento : BrochuraNúmero da edição : 7Ano da edição : 2013\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcUoUN-UsiTf",
        "colab_type": "code",
        "outputId": "d26b2dc8-46bc-4338-ef17-30d82d229878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Exemplo 2: Vetorização por contagem de termos simples com a combinação de unigrama e bigrama no documento lematizado, sem stopwords do SpaCy e modelo de classificação DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import spacy\n",
        "\n",
        "# stopwords SpaCy\n",
        "nlp = spacy.load('pt_core_news_sm')\n",
        "stops = nlp.Defaults.stop_words\n",
        "\n",
        "# vetorização por contagem de termos no documento lematizado\n",
        "vect = CountVectorizer(ngram_range=(1,2), stop_words=stops) # exemplo 2.1: vetorização e combinação de unigrama e bigrama sem stopwords\n",
        "vect.fit(df.text_lemma)\n",
        "text_vect = vect.transform(df.text_lemma)\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(\n",
        "    text_vect, \n",
        "    df[\"categoria\"], \n",
        "    test_size = 0.2,\n",
        "    random_state = 42\n",
        "  )\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "y_prediction = tree.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[E050] Can't find model 'pt'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-16-904784d70c64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# stopwords SpaCy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mstops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDefaults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Projetos\\virtualenvs\\fiap_courses\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Projetos\\virtualenvs\\fiap_courses\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'pt'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsjOD_P5hAIc",
        "colab_type": "code",
        "outputId": "f63a446d-246c-4973-c02a-e0ccf1022c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Exemplo 3: Vetorização por contagem de termos simples com a combinação de unigrama e bigrama no documento com verbos lematizado, sem stopwords do SpaCy e modelo de classificação DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import spacy\n",
        "\n",
        "# stopwords SpaCy\n",
        "nlp = spacy.load('pt')\n",
        "stops = nlp.Defaults.stop_words\n",
        "\n",
        "# vetorização por contagem de termos no documento com os verbos lematizado\n",
        "#vect = CountVectorizer(ngram_range=(1,1), stop_words=stops) # exemplo 3.1: vetorização e combinação de unigrama sem stopwords\n",
        "vect = CountVectorizer(ngram_range=(1,2), stop_words=stops) # exemplo 3.2: vetorização e combinação de unigrama e bigrama sem stopwords\n",
        "vect.fit(df.text_lemma_verbs)\n",
        "text_vect = vect.transform(df.text_lemma_verbs)\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(\n",
        "    text_vect, \n",
        "    df[\"categoria\"], \n",
        "    test_size = 0.2,\n",
        "    random_state = 42\n",
        "  )\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "y_prediction = tree.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG51OO8KlduJ",
        "colab_type": "code",
        "outputId": "21a18b5b-d3ef-48af-e0c3-ea2ea8544d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Exemplo 4: Vetorização por contagem de termos simples com a combinação de unigrama e bigrama no documento com verbos lematizado, sem stopwords do SpaCy e NLTK combinadas e modelo de classificação DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import spacy\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nlp = spacy.load('pt')\n",
        "\n",
        "# stopwords do SpaCy e NLTK combinadas\n",
        "stops = list(set(nlp.Defaults.stop_words).union(set(nltk.corpus.stopwords.words('portuguese'))))\n",
        "#len(stops)\n",
        "\n",
        "# vetorização por contagem de termos no documento com os verbos lematizado\n",
        "vect = CountVectorizer(ngram_range=(1,2), stop_words=stops)\n",
        "vect.fit(df.text_lemma_verbs)\n",
        "text_vect = vect.transform(df.text_lemma_verbs)\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(\n",
        "    text_vect, \n",
        "    df[\"categoria\"], \n",
        "    test_size = 0.2,\n",
        "    random_state = 42\n",
        "  )\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "y_prediction = tree.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGTuFeHdMLCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "9ca47344-01b9-4711-930d-c0a3d3b3fc70"
      },
      "source": [
        "# Exemplo 5: Vetorização por contagem de termos simples com a combinação de unigrama com documentos lematizado, sem stopwords do SpaCy e NLTK combinadas e modelo de classificação DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import spacy\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nlp = spacy.load('pt')\n",
        "\n",
        "# stopwords do SpaCy e NLTK combinadas\n",
        "stops_spacy = nlp.Defaults.stop_words\n",
        "stops_nltk = nltk.corpus.stopwords.words('portuguese')\n",
        "stops = list(set(stops_spacy).union(set(stops_nltk)))\n",
        "\n",
        "# vetorização por contagem de termos no documento lematizado\n",
        "vetorTfidf = TfidfVectorizer(ngram_range=(1,1), use_idf=True, stop_words=stops, norm='l2')\n",
        "#vetorTfidf = TfidfVectorizer(ngram_range=(1,1), use_idf=True, stop_words=stops_spacy, norm='l2')\n",
        "#vetorTfidf = TfidfVectorizer(ngram_range=(1,1), use_idf=True, stop_words=stops_nltk, norm='l2')\n",
        "vetorTfidf.fit(df.text_lemma)\n",
        "text_vect = vetorTfidf.transform(df.text_lemma)\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(\n",
        "    text_vect, \n",
        "    df[\"categoria\"], \n",
        "    test_size = 0.2,\n",
        "    random_state = 42\n",
        "  )\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "y_prediction = tree.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Aula 4 IA PLN - Exercicio.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit ('fiap_courses': venv)",
      "language": "python",
      "name": "python38364bitfiapcoursesvenv44a15e3d501644f2a429407ae7459dbc"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}